{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "## This is a modified SPANISH version of a GPT-2 Notebook from: https://colab.research.google.com/github/mc51/blog_posts/blob/master/doctors_nlp4.ipynb"
      ],
      "metadata": {
        "id": "tJbvhjO4ph1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7Fmtt1m8_GI",
        "outputId": "ba61604a-cf4e-4e9d-833e-e4badd0e0517"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.16.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.13.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.8.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.11.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.2.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.6)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.8)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (5.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.6.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Do this only Google Colab\n",
        "if os.environ.get(\"COLAB_GPU\", False):\n",
        "    !pip install -U datasets transformers\n",
        "\n",
        "import warnings\n",
        "import re\n",
        "import random\n",
        "import datasets\n",
        "import transformers\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "from transformers import AutoTokenizer,TFGPT2LMHeadModel\n",
        "from datasets import Dataset, load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mi-5WjQjv-gH",
        "outputId": "5a345c54-b66a-47ad-e69f-81fa2e6720d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on TPU  ['10.87.242.242:8470']\n",
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.87.242.242:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.87.242.242:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "REPLICAS:  8\n"
          ]
        }
      ],
      "source": [
        "# Try to run on TPU if available\n",
        "# Detect hardware, return appropriate distribution strategy\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "    print(\"Running on TPU \", tpu.cluster_spec().as_dict()[\"worker\"])\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "else:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "VQ30F8BDXIeQ",
        "outputId": "3a21366a-b419-4e62-fb0a-4f517ca3727c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>Sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1134612598014582785</td>\n",
              "      <td>2da generación de cambios !!  Es con @CosseCar...</td>\n",
              "      <td>&lt;|pos|&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1134628742612082688</td>\n",
              "      <td>@gbianchi404 buenísimo!! ya le pasó la yeta!!!</td>\n",
              "      <td>&lt;|pos|&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1134629055582658560</td>\n",
              "      <td>@gbianchi404 Sra se despertó de su letargo sig...</td>\n",
              "      <td>&lt;|pos|&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    id  ... Sentimiento\n",
              "0  1134612598014582785  ...     <|pos|>\n",
              "1  1134628742612082688  ...     <|pos|>\n",
              "2  1134629055582658560  ...     <|pos|>\n",
              "\n",
              "[3 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# read data\n",
        "reviews = pd.read_csv(\"tweets.csv\")\n",
        "reviews.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-H0w7CCpzAR",
        "outputId": "44971c68-0402-4e5e-9ede-a9baf2d387dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<|neu|>    50122\n",
              "<|neg|>    37821\n",
              "<|pos|>    16726\n",
              "Name: Sentimiento, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "reviews[\"Sentimiento\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xz9bGO2AXpZf",
        "outputId": "91b6fe17-130f-4ee0-f8d7-6df06751d799"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 6.98 s, sys: 59.7 ms, total: 7.04 s\n",
            "Wall time: 7.08 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    - remove any html tags (< /br> often found)\n",
        "    - Keep only ASCII + Latin chars, digits and whitespaces\n",
        "    - pad punctuation chars with whitespace\n",
        "    - convert all whitespaces (tabs etc.) to single wspace\n",
        "    \"\"\"\n",
        "    RE_PUNCTUATION = re.compile(\"([!?.,;-])\")\n",
        "    RE_TAGS = re.compile(r\"<[^>]+>\")\n",
        "    RE_ASCII = re.compile(r\"[^A-Za-zÀ-ž,.!?0-9 ]\", re.IGNORECASE)\n",
        "    RE_WSPACE = re.compile(r\"\\s+\", re.IGNORECASE)\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)\n",
        "    text = re.sub(RE_TAGS, \" \", text)\n",
        "    text = re.sub(RE_ASCII, \" \", text)\n",
        "    text = re.sub(RE_PUNCTUATION, r\" \\1 \", text)\n",
        "    text = re.sub(RE_WSPACE, \" \", text)\n",
        "    text = re.sub(r'([!¡]\\s?){3,}', r' $EXCLAMATION$ ', text)\n",
        "    text = re.sub(r'([¿?]\\s?){3,}', r' $QUESTION$ ', text)\n",
        "    text = re.sub(r'(\\.\\s?){3,}', r' $ELLIPSIS$ ', text)\n",
        "    text = re.sub(r'\\b(?:a*(?:(h+|j+)a+|s+)+(h+|j+)?|(?:l+o+)+l+)\\b', r' $LOL$ ', text, flags=re.I)\n",
        "    return text\n",
        "\n",
        "\n",
        "# Clean Comments. Only keep long enough\n",
        "reviews[\"text_clean\"] = reviews.loc[reviews[\"text\"].str.len() > 10, \"text\"]\n",
        "reviews[\"text_clean\"] = reviews[\"text\"].map(\n",
        "    lambda x: clean_text(x) if isinstance(x, str) else x\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "rQh4Q-_QfZpW",
        "outputId": "db490946-9cc3-40e6-ae2a-bb048a7fad58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;|pos|&gt; 2da generación de cambios ! ! Es con C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;|pos|&gt;  gbianchi404 buenísimo ! ! ya le pasó ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  <|pos|> 2da generación de cambios ! ! Es con C...\n",
              "1  <|pos|>  gbianchi404 buenísimo ! ! ya le pasó ..."
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Drop Missing and save to file\n",
        "reviews = reviews.dropna(axis=\"index\", subset=[\"text_clean\"]).reset_index(drop=True)\n",
        "# add rating indicator as first word of comment\n",
        "reviews[\"text_clean\"] = reviews[\"Sentimiento\"] + \" \" + reviews[\"text_clean\"]\n",
        "data = reviews[[\"text_clean\"]]\n",
        "data.columns = [\"text\"]\n",
        "data.to_csv('clean_tweets.csv',index=False)\n",
        "data.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeGF76Oc9FWv",
        "outputId": "1bd0bafd-fb2a-4535-93c8-3f0bf28dda39"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text'],\n",
              "    num_rows: 104669\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Read data from file and load as dataset\n",
        "data = pd.read_csv('clean_tweets.csv')\n",
        "data = Dataset.from_pandas(data)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUxlfURTDwaN",
        "outputId": "c315dc0b-c6a8-4b69-9758-e7b1d26ad32a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "MAX_TOKENS = 128\n",
        "POS_TOKEN = \"<|pos|>\"\n",
        "NEG_TOKEN = \"<|neg|>\"\n",
        "NEU_TOKEN = \"<|neu|>\"\n",
        "BOS_TOKENS = [NEG_TOKEN, POS_TOKEN, NEU_TOKEN]\n",
        "EOS_TOKEN = \"<|endoftext|>\"\n",
        "PAD_TOKEN = \"<|pad|>\"\n",
        "\n",
        "# this will download and initialize the pre trained tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"DeepESP/gpt2-spanish\",\n",
        "    eos_token=EOS_TOKEN,\n",
        "    pad_token=PAD_TOKEN,\n",
        "    max_length=MAX_TOKENS,\n",
        "    is_split_into_words=True,\n",
        ")\n",
        "tokenizer.add_tokens(BOS_TOKENS, special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "f2RlcIYotPeY",
        "outputId": "5c9beec0-af03-4327-d8c3-c5e1020ef11e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['attention_mask', 'input_ids', 'labels'],\n",
            "    num_rows: 104669\n",
            "})\n",
            "CPU times: user 2.3 s, sys: 914 ms, total: 3.21 s\n",
            "Wall time: 40.5 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "output = {}\n",
        "# texts to numeric vectors of MAX_TOKENS\n",
        "def tokenize_function(examples, tokenizer=tokenizer):\n",
        "    # Add start and end token to each comment\n",
        "    examples = [ex + EOS_TOKEN for ex in examples[\"text\"]]\n",
        "    # tokenizer created input_ids and attention_mask as output\n",
        "    output = tokenizer(\n",
        "        examples,\n",
        "        add_special_tokens=True,  # Only adds pad not eos and bos\n",
        "        max_length=MAX_TOKENS,\n",
        "        truncation=True,\n",
        "        pad_to_max_length=True,\n",
        "    )\n",
        "    # shift labels for next token prediction\n",
        "    # set padding token labels to -100 which is ignored in loss computation\n",
        "    output[\"labels\"] = [x[1:] for x in output[\"input_ids\"]]\n",
        "    output[\"labels\"] = [\n",
        "        [-100 if x == tokenizer.pad_token_id else x for x in y]\n",
        "        for y in output[\"labels\"]\n",
        "    ]\n",
        "    # truncate input ids and attention mask to account for label shift\n",
        "    output[\"input_ids\"] = [x[:-1] for x in output[\"input_ids\"]]\n",
        "    output[\"attention_mask\"] = [x[:-1] for x in output[\"attention_mask\"]]\n",
        "    return output\n",
        "\n",
        "\n",
        "data = data.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    num_proc=strategy.num_replicas_in_sync,\n",
        "    remove_columns=[\"text\"],\n",
        "    load_from_cache_file=True,\n",
        ")\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnOz6LJTtSAY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da38ed39-78de-4e63-ead1-18f6dc5585ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached split indices for dataset at tokenized_tweets/cache-f740d94e9bd74194.arrow and tokenized_tweets/cache-4ddc77f14d26f919.arrow\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['attention_mask', 'input_ids', 'labels'],\n",
            "        num_rows: 83735\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['attention_mask', 'input_ids', 'labels'],\n",
            "        num_rows: 20934\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "# Load Inputs and create test and train split\n",
        "data.save_to_disk('tokenized_tweets')\n",
        "data = datasets.load_from_disk('tokenized_tweets')\n",
        "data.set_format(type=\"python\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "data = data.train_test_split(\n",
        "    test_size=0.20, shuffle=True, seed=1, load_from_cache_file=True\n",
        ")\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JXLryO8-Sam",
        "outputId": "2ed6aebc-dc93-43c2-c4d3-d1ebe156684b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 32.1 s, sys: 1.03 s, total: 33.1 s\n",
            "Wall time: 33 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# prepare for use in tensorflow\n",
        "train_tensor_inputs = tf.convert_to_tensor(data[\"train\"][\"input_ids\"])\n",
        "train_tensor_labels = tf.convert_to_tensor(data[\"train\"][\"labels\"])\n",
        "train_tensor_mask = tf.convert_to_tensor(data[\"train\"][\"attention_mask\"])\n",
        "train = tf.data.Dataset.from_tensor_slices(\n",
        "    (\n",
        "        {\"input_ids\": train_tensor_inputs, \"attention_mask\": train_tensor_mask},\n",
        "        train_tensor_labels,\n",
        "    )\n",
        ")\n",
        "\n",
        "test_tensor_inputs = tf.convert_to_tensor(data[\"test\"][\"input_ids\"])\n",
        "test_tensor_labels = tf.convert_to_tensor(data[\"test\"][\"labels\"])\n",
        "test_tensor_mask = tf.convert_to_tensor(data[\"test\"][\"attention_mask\"])\n",
        "test = tf.data.Dataset.from_tensor_slices(\n",
        "    (\n",
        "        {\"input_ids\": test_tensor_inputs, \"attention_mask\": test_tensor_mask},\n",
        "        test_tensor_labels,\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7nvk5ENlSVh"
      },
      "source": [
        "This concludes the data preparation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hcm_3P1glSVh"
      },
      "source": [
        "### Build and train GPT-2 Model\n",
        "\n",
        "Next, we can start defining our model architecture:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fq_m8UVc8sbZ"
      },
      "outputs": [],
      "source": [
        "# Model params\n",
        "BATCH_SIZE_PER_REPLICA = 32\n",
        "EPOCHS = 3\n",
        "INITAL_LEARNING_RATE = 0.001\n",
        "try:\n",
        "    BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
        "except NameError as e:\n",
        "    BATCH_SIZE = BATCH_SIZE_PER_REPLICA\n",
        "BUFFER_SIZE = len(train)\n",
        "\n",
        "# prepare data for consumption\n",
        "train_ds = (\n",
        "    train.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        ")\n",
        "test_ds = test.batch(BATCH_SIZE, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oqFlHCXnT9q",
        "outputId": "ed5066e0-8e55-4afb-adcc-f56c14b79b23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at DeepESP/gpt2-spanish.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tfgpt2lm_head_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " transformer (TFGPT2MainLaye  multiple                 124442880 \n",
            " r)                                                              \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 124,442,880\n",
            "Trainable params: 124,442,880\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Drecreasing learning rate scheduler\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    INITAL_LEARNING_RATE,\n",
        "    decay_steps=300,\n",
        "    decay_rate=0.008,\n",
        "    staircase=True)\n",
        "\n",
        "# initialize model, use_cache=False important! else wrong shape at loss calc\n",
        "with strategy.scope():\n",
        "    model = TFGPT2LMHeadModel.from_pretrained(\"DeepESP/gpt2-spanish\",\n",
        "        use_cache=False,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "    )\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "    model.compile(optimizer=optimizer, loss=model.compute_loss)\n",
        "    model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "JP5DJdA-0ywe",
        "outputId": "68690c98-9bf3-4875-f75c-e7b9a92a978a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' # Stop training when validation acc starts dropping\\n# Save checkpoint of model after each period\\nnow = datetime.now().strftime(\"%Y-%m-%d_%H%M\")\\n# Create callbacks\\ncallbacks = [\\n    tf.keras.callbacks.EarlyStopping(\\n        monitor=\"val_loss\", verbose=1, patience=1, restore_best_weights=True\\n    ),\\n    tf.keras.callbacks.ModelCheckpoint(\\n        \"/content/callbacks/\" + now + \"_GPT2-Model_{epoch:02d}_{val_loss:.4f}.h5\",\\n        monitor=\"val_loss\",\\n        save_best_only=True,\\n        verbose=1,\\n    ),\\n] '"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "''' # Stop training when validation acc starts dropping\n",
        "# Save checkpoint of model after each period\n",
        "now = datetime.now().strftime(\"%Y-%m-%d_%H%M\")\n",
        "# Create callbacks\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\", verbose=1, patience=1, restore_best_weights=True\n",
        "    ),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        \"/content/callbacks/\" + now + \"_GPT2-Model_{epoch:02d}_{val_loss:.4f}.h5\",\n",
        "        monitor=\"val_loss\",\n",
        "        save_best_only=True,\n",
        "        verbose=1,\n",
        "    ),\n",
        "] '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgeHxshi-JQS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdec9643-a300-4c78-c88c-8ca9938561b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Params:\n",
            "batch_size: 256\n",
            "Epochs: 3\n",
            "Step p. Epoch: 327\n",
            "Initial Learning rate: 0.001\n",
            "Epoch 1/3\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2970: StrategyBase.unwrap (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "use `experimental_local_results` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2970: StrategyBase.unwrap (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "use `experimental_local_results` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "327/327 [==============================] - 236s 493ms/step - loss: 3.9224 - val_loss: 3.5298\n",
            "Epoch 2/3\n",
            "327/327 [==============================] - 153s 468ms/step - loss: 3.1907 - val_loss: 3.4976\n",
            "Epoch 3/3\n",
            "327/327 [==============================] - 153s 469ms/step - loss: 3.1569 - val_loss: 3.4975\n",
            "CPU times: user 51.2 s, sys: 3.72 s, total: 55 s\n",
            "Wall time: 9min 5s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Train Model\n",
        "steps_per_epoch = int(BUFFER_SIZE // BATCH_SIZE)\n",
        "print(\n",
        "    f\"Model Params:\\nbatch_size: {BATCH_SIZE}\\nEpochs: {EPOCHS}\\n\"\n",
        "    f\"Step p. Epoch: {steps_per_epoch}\\n\"\n",
        "    f\"Initial Learning rate: {INITAL_LEARNING_RATE}\"\n",
        ")\n",
        "hist = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=test_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GiDHBeCPuPp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc71d0d5-5756-4b24-b830-261296e13469"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        " loss = pd.DataFrame(\n",
        "    {\"train loss\": hist.history[\"loss\"], \"test loss\": hist.history[\"val_loss\"]}\n",
        ").melt()\n",
        "loss[\"epoch\"] = loss.groupby(\"variable\").cumcount() + 1\n",
        "sns.lineplot(x=\"epoch\", y=\"value\", hue=\"variable\", data=loss).set(\n",
        "    title=\"Model loss\",\n",
        "    ylabel=\"\",\n",
        "    xticks=range(1, loss[\"epoch\"].max() + 1),\n",
        "    xticklabels=loss[\"epoch\"].unique(),\n",
        ");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "we_RLH0NSlrR"
      },
      "outputs": [],
      "source": [
        "# Restored Trained Model weights\n",
        "# model.load_weights(PATH_BASE + \"/data/models/2021-03-21_1925_GPT2-Model_03_2.8273.h5\")\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "review = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T65CJ00_DVyV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "5c3e2be9-087e-4593-9bbe-cf5120a4819e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>generated_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;|pos|&gt;  adeladubra El futuro de los Uruguayos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;|pos|&gt;  gbianchi404 Felicitaciones Graciela, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;|pos|&gt;  EsMonicaFA Qué orgullo!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;|pos|&gt; Que orgullo que los de mi confianza no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;|pos|&gt; Vimos este gobierno para seguir avanza...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>&lt;|pos|&gt;  gbianchi404 Todo un éxito.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      generated_text\n",
              "0  <|pos|>  adeladubra El futuro de los Uruguayos...\n",
              "1  <|pos|>  gbianchi404 Felicitaciones Graciela, ...\n",
              "2                 <|pos|>  EsMonicaFA Qué orgullo!! \n",
              "3  <|pos|> Que orgullo que los de mi confianza no...\n",
              "4  <|pos|> Vimos este gobierno para seguir avanza...\n",
              "5               <|pos|>  gbianchi404 Todo un éxito. "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "gen_pos = review(\"<|pos|>\", max_length=150, num_return_sequences=6)\n",
        "pd.DataFrame(gen_pos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGzYpB2sYnk8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4da079c9-7838-418b-ba00-9604b88eb8ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': '<|pos|>  adeladubra El futuro de los Uruguayos, de las manos del pueblo y de la gente, muy poco probable, muy mal perdedor! '},\n",
              " {'generated_text': '<|pos|>  gbianchi404 Felicitaciones Graciela, el mejor país para ti también. '},\n",
              " {'generated_text': '<|pos|>  EsMonicaFA Qué orgullo!! '},\n",
              " {'generated_text': '<|pos|> Que orgullo que los de mi confianza nos compartan y recuerden ese día de cumpleaños de la CosseCarolina  $EXCLAMATION$ Por dios  $EXCLAMATION$ '},\n",
              " {'generated_text': '<|pos|> Vimos este gobierno para seguir avanzando desde nuestro lanzamiento!! '},\n",
              " {'generated_text': '<|pos|>  gbianchi404 Todo un éxito. '}]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "gen_pos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Na_rumQpdVsP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "ff529d93-4806-452b-a92f-11a6181b4c10"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>generated_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;|neg|&gt;  CosseCarolina No te veo tan preocupad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;|neg|&gt;  gbianchi404 Son unos atrevidos que no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;|neg|&gt;  gbianchi404 Sos una vergüenza y te fa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;|neg|&gt;  beatrizargimon Un poco más largo el a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;|neg|&gt;  CosseCarolina Cómo se llama esto?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>&lt;|neg|&gt;  EsMonicaFA Esta vieja loca, no merece...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      generated_text\n",
              "0  <|neg|>  CosseCarolina No te veo tan preocupad...\n",
              "1  <|neg|>  gbianchi404 Son unos atrevidos que no...\n",
              "2  <|neg|>  gbianchi404 Sos una vergüenza y te fa...\n",
              "3  <|neg|>  beatrizargimon Un poco más largo el a...\n",
              "4        <|neg|>  CosseCarolina Cómo se llama esto? \n",
              "5  <|neg|>  EsMonicaFA Esta vieja loca, no merece..."
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "gen_neg = review(\"<|neg|>\", max_length=150, num_return_sequences=6)\n",
        "pd.DataFrame(gen_neg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZmJEr9eXvvs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55950a53-7e75-44d6-9472-57204d5c11e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': '<|neg|>  CosseCarolina No te veo tan preocupada porque cuando vas a condenar los DDHH se van a ir porque los que se van no los quieren. '},\n",
              " {'generated_text': '<|neg|>  gbianchi404 Son unos atrevidos que nos representan, no les interesa'},\n",
              " {'generated_text': '<|neg|>  gbianchi404 Sos una vergüenza y te falto la vida '},\n",
              " {'generated_text': '<|neg|>  beatrizargimon Un poco más largo el artículo del reglamento por favor, te pido que expliques si estás mal de la cabeza, no seas hipócrita'},\n",
              " {'generated_text': '<|neg|>  CosseCarolina Cómo se llama esto? '},\n",
              " {'generated_text': '<|neg|>  EsMonicaFA Esta vieja loca, no merece nada. '}]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "gen_neg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kt_yWL2lgNoG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "ab7a6d7d-ed2a-4bc5-adc4-1e90f9068be1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>generated_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;|neu|&gt;  $LOL$  en serio??</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;|neu|&gt;  CosseCarolina En este video tu amigo ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;|neu|&gt;  gbianchi404 Graciela no. Ya lo sabemo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;|neu|&gt;  CosseCarolina Caro te parece correcto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;|neu|&gt;  CosseCarolina En vez de apoyar la ref...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>&lt;|neu|&gt; Muy clara lauraraffo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      generated_text\n",
              "0                        <|neu|>  $LOL$  en serio?? \n",
              "1  <|neu|>  CosseCarolina En este video tu amigo ...\n",
              "2  <|neu|>  gbianchi404 Graciela no. Ya lo sabemo...\n",
              "3  <|neu|>  CosseCarolina Caro te parece correcto...\n",
              "4  <|neu|>  CosseCarolina En vez de apoyar la ref...\n",
              "5                       <|neu|> Muy clara lauraraffo"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "gen_neu = review(\"<|neu|>\", max_length=150, num_return_sequences=6)\n",
        "pd.DataFrame(gen_neu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmLaiYLQgUmG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d844231-fe14-472f-86d0-86bc7ba8d26a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': '<|neu|>  $LOL$  en serio?? '},\n",
              " {'generated_text': '<|neu|>  CosseCarolina En este video tu amigo dijo que el costo era posible!! '},\n",
              " {'generated_text': '<|neu|>  gbianchi404 Graciela no. Ya lo sabemos. Creo que a Ud. le interesa la educación de muchas personas. '},\n",
              " {'generated_text': '<|neu|>  CosseCarolina Caro te parece correcto que hablás con coherencia? '},\n",
              " {'generated_text': '<|neu|>  CosseCarolina En vez de apoyar la reforma  $ELLIPSIS$ es de cuarta y sin la LUC nadie les va a escuchar. '},\n",
              " {'generated_text': '<|neu|> Muy clara lauraraffo'}]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "gen_neu"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "GPT2-Spanish-Tweets.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}